import pickle
from sklearn.model_selection import train_test_split, KFold, StratifiedKFold
from .context import get_dataset_folder, XySet
from .dataset import *
from .specific import *


def prepare_dataset_sets(dt):
    """
    creates the train & test set, and the evaluation set per folds

    :param dt: dataset
    :return:
    """
    # create train & test set
    X, y, X_train, X_test, y_train, y_test, X_submit, id_submit = __create_train_test(dt)

    # prepare y values
    y, y_train, y_test = __prepare_y(dt, y, y_train, y_test)

    # create cv folds
    cv_folds = __create_cv(dt, X_train, y_train)

    # prepare and store eval set
    y_eval_list, y_eval, idx_eval = __store_eval_set(dt, y_train, y_test, cv_folds)

    # then store all these results in a pickle store
    ds = XySet(X, y, X_train, y_train, X_test, y_test, X_submit, id_submit, cv_folds, y_eval_list, y_eval, idx_eval)
    pickle.dump(ds, open(get_dataset_folder(dt.dataset_id) + '/data/eval_set.pkl', 'wb'))


def __create_train_test(dataset):
    dataset = get_dataset(dataset.dataset_id)
    # feature engineering
    fe = get_feature_engineering(dataset.dataset_id)
    data_train = dataset.get_data()
    if fe != '':
        data_train = apply_feature_engineering(dataset.dataset_id, data_train)

    # update columns
    dataset.update_features(data_train)
    dataset.update_calc()
    dataset.save(dataset.dataset_id)

    # TODO: split according to val_col
    # split into train & test set
    if dataset.with_test_set:
        data_test = dataset.get_data('test')
        if fe != '':
            data_test = apply_feature_engineering(dataset.dataset_id, data_test)

        X_train = data_train[dataset.x_cols]
        y_train = data_train[dataset.y_col].values

        X_test = data_test[dataset.x_cols]
        y_test = data_test[dataset.y_col].values

        X = X_train.copy()
        y = y_train.copy()
    else:
        X = data_train[dataset.x_cols]
        y = data_train[dataset.y_col].values

        # test set generated by split with holdout ratio
        if dataset.problem_type == 'regression':
            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=dataset.holdout_ratio,
                                                                shuffle=dataset.val_col_shuffle, random_state=0)
        else:
            try:
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=dataset.holdout_ratio,
                                                                    shuffle=dataset.val_col_shuffle,
                                                                    stratify=y,
                                                                    random_state=0)
            except:
                # may fail if two few classes -> split without stratify
                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=dataset.holdout_ratio,
                                                                    shuffle=dataset.val_col_shuffle,
                                                                    random_state=0)

    # submit data
    if dataset.filename_submit != '':
        df = dataset.get_data('submit')
        if fe != '':
            df = apply_feature_engineering(dataset.dataset_id, df)
        X_submit = df[dataset.x_cols]
        id_submit = df[dataset.col_submit].values
    else:
        X_submit = []
        id_submit = []

    return X, y, X_train, X_test, y_train, y_test, X_submit, id_submit


def __create_cv(dataset, X_train, y_train):
    # generate cv folds
    # TODO: split according to val_col
    if dataset.problem_type == 'classification':
        skf = StratifiedKFold(n_splits=dataset.cv_folds, shuffle=dataset.val_col_shuffle, random_state=0)
        cv_folds = [(train_index, eval_index) for train_index, eval_index in skf.split(X_train, y_train)]
    else:
        skf = KFold(n_splits=dataset.cv_folds, shuffle=dataset.val_col_shuffle, random_state=0)
        cv_folds = [(train_index, eval_index) for train_index, eval_index in skf.split(X_train)]
    return cv_folds


def __store_eval_set(dataset, y_train, y_test, cv_folds):
    y_eval_list = []
    i_eval_list = []
    # stores eval set
    for i, (train_index, eval_index) in enumerate(cv_folds):
        pickle.dump(y_train[train_index], open(get_dataset_folder(dataset.dataset_id) + '/y_train_%d.pkl' % i, 'wb'))
        pickle.dump(y_train[eval_index], open(get_dataset_folder(dataset.dataset_id) + '/y_eval_%d.pkl' % i, 'wb'))
        y_eval_list.append(y_train[eval_index])
        i_eval_list.append(eval_index)

    # stores test set
    pickle.dump(y_test, open(get_dataset_folder(dataset.dataset_id) + '/y_test.pkl', 'wb'))

    # generate y_eval
    y_eval = np.concatenate(y_eval_list, axis=0)

    # store y_eval
    pickle.dump(y_train, open(get_dataset_folder(dataset.dataset_id) + '/y_eval.pkl', 'wb'))

    return y_eval_list, y_eval, np.concatenate(i_eval_list, axis=0)


def __prepare_y(dataset, y, y_train, y_test):
    # pre-processing of y: categorical
    if dataset.problem_type == 'classification':
        # encode class values as integers
        map_y = {str(x): i for i, x in enumerate(dataset.y_class_names)}
        y = np.array([map_y[str(x)] if str(x) in map_y else 0 for x in y])
        y_train = np.array([map_y[str(x)] if str(x) in map_y else 0 for x in y_train])
        y_test = np.array([map_y[str(x)] if str(x) in map_y else 0 for x in y_test])
    return y, y_train, y_test

